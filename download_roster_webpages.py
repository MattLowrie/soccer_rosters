"""Downloads roster webpages.

URLs ar read from the CSV data generated by collect_roster_urls.py.

These modules are required:
pip install --user beautifulsoup4
pip install --user requests
pip install --user user_agent
"""
import argparse
from bs4 import BeautifulSoup as bs
import csv
import logging
import requests
import sys
from urllib.parse import urlparse
from urllib.parse import urlunparse
import user_agent

from util import roster_file_util

LOGFILE = '/tmp/download_roster_webpages.log'
LOGGER = None
# Some roster web servers only return a response if the request headers simulate
# a real web browser.
HTTP_HEADERS = {
  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
  'Accept-Encoding': 'gzip, deflate',
  'Accept-Language': 'en-US,en;q=0.9'
}
DL_ERR_MSG = bs('An error occurred trying to download this web page. Please '
    'check the log file and re-run the download_roster_webpages.py script '
    'for this school using the --schools= flag.', 'html.parser')

def _build_request_args(url):
  """Creates a request args dict to pass to requests.get().

  The request headers simulate a real browser.
  """
  http_headers = {'User-Agent': user_agent.generate_user_agent()}
  http_headers.update(HTTP_HEADERS)
  request_args = {
    'url': url,
    'headers': http_headers,
  }
  return request_args


def get_webpage_content(urls):
  """Calls each roster URL and returns the content as a BeautifulSoup instance.

  Note: Any request failures will be logged as an ERROR to the log file.

  Arguments:
    urls: A list of urls to pass to requests.get().

  Returns:
    A list of BeautifulSoup instances which correspond to the list of urls.
  """
  soups = []
  for url in urls:
    try:
      req_args = _build_request_args(url)
      resp = requests.get(**req_args)
      if resp.status_code == 200:
        soups.append(bs(resp.content, 'html.parser'))
      else:
        LOGGER.error('Status code %d for %s', resp.status_code, req_args['url'])
        LOGGER.error('HTTP reason: %s', resp.reason)
        LOGGER.error('HTTP response headers:')
        LOGGER.error(resp.raw.getheaders())
        # Keep the length of the content list equal to the URL list
        soups.append(DL_ERR_MSG)
    except requests.exceptions.ConnectionError:
      LOGGER.error('Connection error for: %s', req_args['url'])
      # Keep the length of the content list equal to the URL list
      soups.append(DL_ERR_MSG)
  return soups


def save_files(soups, schools, output_dir):
  """Save the roster web page locally.

  Arguments:
    soups: A list of BeaufitfulSoup instances, one for each corresponding
        school in the list of schools.
    schools: A list of strings of each school name. The school name is used as
        the file name for the saved web page.
    output_dir: The local directory to save all web pages.
  """
  # Now save each webpage to a local file.
  for i, soup in enumerate(soups):
    file_name = schools[i].replace(' ', '_')
    roster_file_util.write_file(file_name + '.webpage',
                                soup.prettify(),
                                dir_path=output_dir)


def main():
  school_filter = []
  if flags.schools:
    school_filter = [f.strip() for f in flags.schools.split(',')]

  schools, _, _, _, _, _, urls = \
      roster_file_util.read_school_info_file(flags.input_file, school_filter)

  soups = get_webpage_content(urls)

  save_files(soups, schools, flags.output_dir)


def _set_arguments():
  parser = argparse.ArgumentParser()
  parser.add_argument('-i', '--input_file', metavar='FILENAME',
                      default='ncaa_d1_womens_soccer_programs.csv',
                      help='CSV file to read school information in from.')
  parser.add_argument('-o', '--output_dir', metavar='FILENAME',
                      default='roster_webpages',
                      help='The directory to save all webpage files into.'
                        'The directory is relative to the current working'
                        'directory.')
  parser.add_argument('--schools', metavar='"SCHOOL 1, SCHOOL 2, SCHOOL 3"',
                      help='A comma-separated list of schools to output.')
  return parser.parse_args()


def _set_logger():
  fmt = '%(asctime)s,%(msecs)-3d %(levelname)-8s %(filename)s:%(lineno)d -> %(message)s'
  logging.basicConfig(level=logging.DEBUG,
                      format=fmt,
                      datefmt='%m-%d %H:%M:%S',
                      filename=LOGFILE,
                      filemode='w')
  return logging.getLogger(__name__)


if __name__ == '__main__':
  flags = _set_arguments()
  LOGGER = _set_logger()
  main()
